{"env_info": "sys.platform: linux\nPython: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]\nCUDA available: True\nGPU 0: Tesla V100-SXM2-32GB\nCUDA_HOME: /data/apps/cuda/10.2\nNVCC: Cuda compilation tools, release 10.2, V10.2.8\nGCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\nPyTorch: 1.11.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 7.6.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.12.0\nOpenCV: 4.7.0\nMMCV: 1.7.1\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.2\nMMDetection: 2.28.1+", "config": "model = dict(\n    type='RetinaNet',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(\n            type='Pretrained',\n            checkpoint=\n            '/data/home/scv9611/run/mmdetection/checkpoint/resnet50-0676ba61.pth'\n        )),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=1,\n        add_extra_convs='on_input',\n        num_outs=5),\n    bbox_head=dict(\n        type='RetinaHead',\n        num_classes=20,\n        in_channels=256,\n        stacked_convs=4,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            octave_base_scale=4,\n            scales_per_octave=3,\n            ratios=[0.5, 1.0, 2.0],\n            strides=[8, 16, 32, 64, 128]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[0.0, 0.0, 0.0, 0.0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='FocalLoss',\n            use_sigmoid=True,\n            gamma=2.0,\n            alpha=0.25,\n            loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    train_cfg=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.5,\n            neg_iou_thr=0.4,\n            min_pos_iou=0,\n            ignore_iof_thr=-1),\n        allowed_border=-1,\n        pos_weight=-1,\n        debug=False),\n    test_cfg=dict(\n        nms_pre=1000,\n        min_bbox_size=0,\n        score_thr=0.05,\n        nms=dict(type='nms', iou_threshold=0.5),\n        max_per_img=100))\ndataset_type = 'VOCDataset'\ndata_root = '/data/public/PascalVOC/2012/VOC2012/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1000, 600),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=36,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=3,\n        dataset=dict(\n            type='VOCDataset',\n            ann_file=\n            '/data/public/PascalVOC/2012/VOC2012/ImageSets/Main/train.txt',\n            img_prefix='/data/public/PascalVOC/2012/VOC2012/',\n            pipeline=[\n                dict(type='LoadImageFromFile'),\n                dict(type='LoadAnnotations', with_bbox=True),\n                dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),\n                dict(type='RandomFlip', flip_ratio=0.5),\n                dict(\n                    type='Normalize',\n                    mean=[123.675, 116.28, 103.53],\n                    std=[58.395, 57.12, 57.375],\n                    to_rgb=True),\n                dict(type='Pad', size_divisor=32),\n                dict(type='DefaultFormatBundle'),\n                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n            ])),\n    val=dict(\n        type='VOCDataset',\n        ann_file='/data/public/PascalVOC/2012/VOC2012/ImageSets/Main/val.txt',\n        img_prefix='/data/public/PascalVOC/2012/VOC2012/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1000, 600),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='VOCDataset',\n        ann_file='/data/public/PascalVOC/2012/VOC2012/ImageSets/Main/val.txt',\n        img_prefix='/data/public/PascalVOC/2012/VOC2012/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1000, 600),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nevaluation = dict(interval=1, metric='mAP')\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\nopencv_num_threads = 0\nmp_start_method = 'fork'\nauto_scale_lr = dict(enable=False, base_batch_size=16)\noptimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='step', step=[3])\nrunner = dict(type='EpochBasedRunner', max_epochs=4)\nwork_dir = './work_dirs/voc2012'\nauto_resume = False\ngpu_ids = [0]\n", "seed": 1418355155, "exp_name": "voc2012.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.01, "memory": 27288, "data_time": 0.13295, "loss_cls": 1.14751, "loss_bbox": 0.6479, "loss": 1.7954, "time": 2.08555}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.01, "memory": 27288, "data_time": 0.06922, "loss_cls": 1.0246, "loss_bbox": 0.60787, "loss": 1.63248, "time": 1.99662}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.01, "memory": 27288, "data_time": 0.07004, "loss_cls": 0.90786, "loss_bbox": 0.57588, "loss": 1.48374, "time": 2.01812}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.01, "memory": 27288, "data_time": 0.06976, "loss_cls": 1.13842, "loss_bbox": 0.57377, "loss": 1.71219, "time": 2.0105}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.01, "memory": 27288, "data_time": 0.07508, "loss_cls": 1.11504, "loss_bbox": 0.5411, "loss": 1.65613, "time": 1.99973}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.01, "memory": 27288, "data_time": 0.07231, "loss_cls": 1.10414, "loss_bbox": 0.53486, "loss": 1.639, "time": 2.01458}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.01, "memory": 27288, "data_time": 0.0702, "loss_cls": 0.98962, "loss_bbox": 0.53005, "loss": 1.51967, "time": 2.01265}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.01, "memory": 27288, "data_time": 0.07329, "loss_cls": 1.11274, "loss_bbox": 0.48889, "loss": 1.60163, "time": 2.00549}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.01, "memory": 27288, "data_time": 0.07806, "loss_cls": 0.95535, "loss_bbox": 0.47907, "loss": 1.43442, "time": 2.04396}
{"mode": "val", "epoch": 1, "iter": 5823, "lr": 0.01, "mAP": 0.02779, "AP50": 0.028}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.01, "memory": 27288, "data_time": 0.13006, "loss_cls": 0.66342, "loss_bbox": 0.4392, "loss": 1.10262, "time": 2.06832}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 0.01, "memory": 27288, "data_time": 0.06909, "loss_cls": 0.65785, "loss_bbox": 0.43425, "loss": 1.0921, "time": 1.99782}
{"mode": "train", "epoch": 2, "iter": 150, "lr": 0.01, "memory": 27288, "data_time": 0.0759, "loss_cls": 0.65697, "loss_bbox": 0.42068, "loss": 1.07765, "time": 2.00488}
{"mode": "train", "epoch": 2, "iter": 200, "lr": 0.01, "memory": 27288, "data_time": 0.07011, "loss_cls": 0.63987, "loss_bbox": 0.406, "loss": 1.04588, "time": 2.0057}
{"mode": "train", "epoch": 2, "iter": 250, "lr": 0.01, "memory": 27288, "data_time": 0.07052, "loss_cls": 0.59654, "loss_bbox": 0.40565, "loss": 1.00219, "time": 2.02284}
{"mode": "train", "epoch": 2, "iter": 300, "lr": 0.01, "memory": 27288, "data_time": 0.07067, "loss_cls": 0.53594, "loss_bbox": 0.38198, "loss": 0.91792, "time": 2.01058}
{"mode": "train", "epoch": 2, "iter": 350, "lr": 0.01, "memory": 27288, "data_time": 0.06887, "loss_cls": 0.52215, "loss_bbox": 0.37657, "loss": 0.89872, "time": 2.0124}
{"mode": "train", "epoch": 2, "iter": 400, "lr": 0.01, "memory": 27288, "data_time": 0.07064, "loss_cls": 0.52487, "loss_bbox": 0.37675, "loss": 0.90162, "time": 1.98374}
{"mode": "train", "epoch": 2, "iter": 450, "lr": 0.01, "memory": 27288, "data_time": 0.07049, "loss_cls": 0.50127, "loss_bbox": 0.36767, "loss": 0.86894, "time": 2.01962}
{"mode": "val", "epoch": 2, "iter": 5823, "lr": 0.01, "mAP": 0.11687, "AP50": 0.117}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.01, "memory": 27288, "data_time": 0.13845, "loss_cls": 0.46627, "loss_bbox": 0.3516, "loss": 0.81787, "time": 2.07835}
{"mode": "train", "epoch": 3, "iter": 100, "lr": 0.01, "memory": 27288, "data_time": 0.07127, "loss_cls": 0.45805, "loss_bbox": 0.34829, "loss": 0.80635, "time": 2.01688}
{"mode": "train", "epoch": 3, "iter": 150, "lr": 0.01, "memory": 27288, "data_time": 0.07339, "loss_cls": 0.45091, "loss_bbox": 0.33876, "loss": 0.78967, "time": 2.01793}
{"mode": "train", "epoch": 3, "iter": 200, "lr": 0.01, "memory": 27288, "data_time": 0.07395, "loss_cls": 0.43262, "loss_bbox": 0.33612, "loss": 0.76873, "time": 1.98601}
{"mode": "train", "epoch": 3, "iter": 250, "lr": 0.01, "memory": 27288, "data_time": 0.07753, "loss_cls": 0.43576, "loss_bbox": 0.33152, "loss": 0.76728, "time": 2.00903}
{"mode": "train", "epoch": 3, "iter": 300, "lr": 0.01, "memory": 27288, "data_time": 0.07639, "loss_cls": 0.4142, "loss_bbox": 0.32945, "loss": 0.74365, "time": 2.01511}
{"mode": "train", "epoch": 3, "iter": 350, "lr": 0.01, "memory": 27288, "data_time": 0.07624, "loss_cls": 0.40507, "loss_bbox": 0.32908, "loss": 0.73414, "time": 2.01678}
{"mode": "train", "epoch": 3, "iter": 400, "lr": 0.01, "memory": 27288, "data_time": 0.07436, "loss_cls": 0.39105, "loss_bbox": 0.31859, "loss": 0.70964, "time": 2.01522}
{"mode": "train", "epoch": 3, "iter": 450, "lr": 0.01, "memory": 27288, "data_time": 0.07261, "loss_cls": 0.38497, "loss_bbox": 0.3172, "loss": 0.70217, "time": 2.0214}
{"mode": "val", "epoch": 3, "iter": 5823, "lr": 0.01, "mAP": 0.30717, "AP50": 0.307}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 0.001, "memory": 27288, "data_time": 0.13275, "loss_cls": 0.33094, "loss_bbox": 0.28807, "loss": 0.61901, "time": 2.0638}
{"mode": "train", "epoch": 4, "iter": 100, "lr": 0.001, "memory": 27288, "data_time": 0.07223, "loss_cls": 0.31531, "loss_bbox": 0.28195, "loss": 0.59726, "time": 2.00985}
{"mode": "train", "epoch": 4, "iter": 150, "lr": 0.001, "memory": 27288, "data_time": 0.07264, "loss_cls": 0.31537, "loss_bbox": 0.27758, "loss": 0.59294, "time": 2.02663}
{"mode": "train", "epoch": 4, "iter": 200, "lr": 0.001, "memory": 27288, "data_time": 0.07355, "loss_cls": 0.31309, "loss_bbox": 0.28084, "loss": 0.59393, "time": 2.03823}
{"mode": "train", "epoch": 4, "iter": 250, "lr": 0.001, "memory": 27288, "data_time": 0.07296, "loss_cls": 0.30601, "loss_bbox": 0.27287, "loss": 0.57889, "time": 2.00177}
{"mode": "train", "epoch": 4, "iter": 300, "lr": 0.001, "memory": 27288, "data_time": 0.07489, "loss_cls": 0.31017, "loss_bbox": 0.27474, "loss": 0.58491, "time": 2.02629}
{"mode": "train", "epoch": 4, "iter": 350, "lr": 0.001, "memory": 27288, "data_time": 0.07409, "loss_cls": 0.30604, "loss_bbox": 0.2759, "loss": 0.58194, "time": 2.01089}
{"mode": "train", "epoch": 4, "iter": 400, "lr": 0.001, "memory": 27288, "data_time": 0.07468, "loss_cls": 0.3069, "loss_bbox": 0.27318, "loss": 0.58007, "time": 2.011}
{"mode": "train", "epoch": 4, "iter": 450, "lr": 0.001, "memory": 27288, "data_time": 0.07864, "loss_cls": 0.30107, "loss_bbox": 0.27324, "loss": 0.57431, "time": 2.02329}
{"mode": "val", "epoch": 4, "iter": 5823, "lr": 0.001, "mAP": 0.36971, "AP50": 0.37}
